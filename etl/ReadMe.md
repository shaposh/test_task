## Телеграмм бот
Ссылка на бота - [t.me/ETL_report_test_bot](https://t.me/ETL_report_test_bot)

### Фунционал
Telegram-боту может быть передан параметр, в зависимости от которого отчет будет сформирован с различной детализацией:

- **/report** - (аналогично **/report SUB**)
- **/report SUB**
- **/report MO**
- **/report GTIN**
- **/report SER**

Также при указании суффикса параметра _NOW расчет средней просрочки в днях будет осуществлен не от количества дней, хранящихся в таблице, а от количества дней равному разнице между датой построения отчета и датой истечения срока годности препарата.
- **/report SUB_NOW**
- **/report MO_NOW**
- **/report GTIN_NOW**
- **/report SER_NOW**


Выполняется  вычисление среднего, а не средневзвешенного значения дней прострочки, однако и этот режим может быть дополнительно имплементирован в функционал без изменения исходных py-файлов путем модификации на сервере БД хранимой процедуры, отвечающей за формирование отчета)

### Конфигурационный файл - *conf.yml*
```yaml
# Путь к файлу с импортируемыми файлами
XLS_FILENAME: 'data/ETL.xlsx'

# Строка, содержащая параметры соединения к базе данных
CONNECTION_STRING: 'host=localhost, port=5432, dbname=etl user=postgres password=54749014'

# Уникальный токен, необходимый для работы Telegram-бота
BOT_TOKEN: '6305159129:AAHIihAeYQSCeo3zYVHm_mDoARxfrHbfMSA'

# Флаг, определяющий нужно ли очищать таблицу БД перед выполнением импорта. При значении параметра
CLEAR_TABLE_BEFORE_IMPORT: True


#Данные будут обновлены, исходя из предположения, что набор полей ИНН-ГТИН-Серия-ТипВыводаИзОборота однозначно идентифицируют запись
#CLEAR_TABLE_BEFORE_IMPORT: False
```

### Утилита импорта данных - *etl_import.py*

Читает настройки расположения файла с данными, режима работы и строки подключения к БД из conf.yml

При заданной опции CLEAR_TABLE_BEFORE_IMPORT: True предварительно очищает таблицу с данными путем вызова функции БД public.overdue_clear()

Затем для каждой строки с данными в Excel вызывает процедуру БД overdue_import, которая либо добавляет запись в таблицу overdue, либо обновляет данные по уникальному ключу overdue_idx_inn_gtin_ser_outtype, созданному по полям, соответствующим данным ИНН-ГТИН-Серия-ТипВыводаИзОборота. 

Поле verdate таблицы overdue содержит информацию о дате-времени импорта (или обновления) для каждой записи с данными

Поле isvalid таблицы overdue содержит информацию о непротиворечивости данных в полях, соответствующих зависящим друг от друга колонкам КоличествоДозВУпаковке, КоличествоУпаковок, КоличествоДоз

Заполнение полей verdate и isvalid производиться на уровне БД триггером overdue$version (не требуется для работы функционала, однако является типовым решением при реализации задач импорта)

При запуске утилита etl_import.py выводит информацию о времени выполнения каждого этапа (Чтение данных из Excel-таблицы, Подключение к БД, Очистка Таблицы (если задано опцией), Импорт Данных)

### Реализация выдачи отчетов через Telegram-bot -  *etl_telegram.py*

Читает настройки строки подключения к БД и значения Telegram-token из conf.yml

Валидное значение для опции BOT_TOKEN файла conf.yml может быть получено 
https://t.me/BotFather токен будет выдан после указание имени бота.

Данные для отчета, возвращаемого ботом формируются процедурой overdue_report

При указании параметра в чат-боте данный параметр передается в overdue_report
 (входной параметр i_mode)

Подобный подход позволяет изменить логику построения отчета (а также добавить новый вид отчета) не выполняя Deploy – путем изменения хранимой процедуры на сервере БД. 

В реальных проектах также добавляется процедура, возвращающая имя отчета, мэппинг «имена столбцов сформированного отчета – поля процедуры»,  возможно имя некого файла-шаблона, что позволяет добавлять-модифицировать отчеты также не выполняя deploy

### Docker files
```dockerfile
    version: '3.8'
#   Докер образ для psql
    services:
      db:
        image: postgres:14.1-alpine
        restart: always
#       Устанавливаем логин и пароль
        environment:
          - POSTGRES_USER=postgres
          - POSTGRES_PASSWORD=postgres
        ports:
          - '5432:5432'
        volumes: 
          - db:/var/lib/postgresql/data
#       Добавляем инициализацию базы данных с помощью заранее написанного скрипта  
          - ./data/etl_db.sql:/docker-entrypoint-initdb.d/create_tables.sql
#    Добавляем в compose запуск скрипта инииалзиции и поднятия бота
      python_script:
        build: 
          context: .
          dockerfile: Dockerfile
        depends_on:
          - db
        links:
          - db
    volumes:
      db:
        driver: local
```